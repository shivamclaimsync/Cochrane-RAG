{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Multi-Level Chunking: Complete Interactive Tutorial\n",
    "\n",
    "Welcome! This notebook will help you understand **multi-level chunking** - a powerful technique for building better RAG systems.\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "1. What is chunking and why it matters\n",
    "2. Problems with traditional single-level chunking\n",
    "3. How multi-level chunking works\n",
    "4. Step-by-step search process with real examples\n",
    "5. Hands-on exercises to test your understanding\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [The Problem with Traditional Chunking](#problem)\n",
    "3. [Understanding Multi-Level Chunking](#understanding)\n",
    "4. [Practical Example](#example)\n",
    "5. [How Search Works](#search)\n",
    "6. [Complete Query Flow](#flow)\n",
    "7. [Interactive Exercises](#exercises)\n",
    "8. [Summary](#summary)\n",
    "\n",
    "---\n",
    "**Time to complete**: 30-45 minutes\n",
    "\n",
    "**Prerequisites**: Basic understanding of RAG systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "### What is Chunking?\n",
    "\n",
    "**Chunking** is the process of breaking down large documents into smaller pieces for information retrieval.\n",
    "\n",
    "### Why Do We Need It?\n",
    "\n",
    "```\n",
    "Problem: A 10,000-word medical paper\n",
    "   ‚Üì\n",
    "LLM can only process ~8,000 tokens at once\n",
    "   ‚Üì\n",
    "Solution: Break it into manageable chunks\n",
    "   ‚Üì\n",
    "Search only relevant chunks\n",
    "   ‚Üì\n",
    "Give LLM only what it needs\n",
    "```\n",
    "\n",
    "### Real-World Analogy\n",
    "\n",
    "Think of a **medical textbook**:\n",
    "\n",
    "- üìö **Book** (Level 1): Overview of all topics\n",
    "- üìñ **Chapters** (Level 2): Major disease categories  \n",
    "- üìÑ **Sections** (Level 3): Specific diseases\n",
    "- üìù **Paragraphs** (Level 4): Detailed symptoms, treatments, statistics\n",
    "\n",
    "When someone asks \"What's the treatment for pneumonia?\", you don't read the entire book - you go straight to the relevant paragraph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. The Problem with Traditional Chunking <a name=\"problem\"></a>\n",
    "\n",
    "### Traditional Approach\n",
    "\n",
    "Most RAG systems use **fixed-size chunks**:\n",
    "\n",
    "```\n",
    "Document (10,000 words)\n",
    "    ‚Üì\n",
    "Split every 500 words\n",
    "    ‚Üì\n",
    "Chunk 1 | Chunk 2 | Chunk 3 | ... | Chunk 20\n",
    "```\n",
    "\n",
    "### Problems:\n",
    "\n",
    "| Problem | Example |\n",
    "|---------|----------|\n",
    "| **Lost Context** | \"The p-value was\" [CHUNK 1] <br> \"<0.001 indicating...\" [CHUNK 2] |\n",
    "| **Fixed Size** | Important paragraph = Same size as filler text |\n",
    "| **No Hierarchy** | Can't tell if chunk is intro or conclusion |\n",
    "| **Poor Retrieval** | Hard to get both overview AND details |\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Chunking Example\n",
    "\n",
    "sample_doc = \"\"\"\n",
    "Title: Antifungal Therapies for ABPA in Cystic Fibrosis\n",
    "\n",
    "Abstract Background: Allergic bronchopulmonary aspergillosis (ABPA) is a common \n",
    "complication in cystic fibrosis patients causing significant morbidity.\n",
    "\n",
    "Objectives: To assess the efficacy of antifungal therapies for ABPA.\n",
    "\n",
    "Methods: Randomized controlled trial. Participants: 45 cystic fibrosis patients \n",
    "with ABPA. Intervention: Itraconazole 200mg twice daily for 16 weeks.\n",
    "\n",
    "Results: Mean FEV1% predicted improved by 12.3% (95% CI: 8.7-15.9, p<0.001) \n",
    "in the itraconazole group. Secondary outcomes: 40% reduction in exacerbation \n",
    "frequency (p=0.02). Adverse events: Nausea (23%), vomiting (15%), elevated \n",
    "liver enzymes (8%).\n",
    "\"\"\"\n",
    "\n",
    "def traditional_chunk(text, words_per_chunk=30):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+words_per_chunk]) \n",
    "            for i in range(0, len(words), words_per_chunk)]\n",
    "\n",
    "chunks = traditional_chunk(sample_doc)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CHUNK {i}\")\n",
    "    print('='*70)\n",
    "    print(chunk)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  PROBLEMS:\")\n",
    "print(\"  1. Statistical data split across chunks\")\n",
    "print(\"  2. No context about what section each chunk belongs to\")\n",
    "print(\"  3. Can't tell which chunks are more important\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Understanding Multi-Level Chunking <a name=\"understanding\"></a>\n",
    "\n",
    "### The Solution: Hierarchical Chunking\n",
    "\n",
    "Instead of fixed-size chunks, create a **hierarchy**:\n",
    "\n",
    "```\n",
    "Level 1: DOCUMENT\n",
    "‚îú‚îÄ‚îÄ Level 2: ABSTRACT SECTION\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Level 3: Background Subsection\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Level 4: \"ABPA is a common complication...\"\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Level 3: Objectives Subsection\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Level 4: \"To assess efficacy...\"\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Level 3: Methods Subsection\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ Level 4: \"Randomized controlled trial...\"\n",
    "‚îú‚îÄ‚îÄ Level 2: RESULTS SECTION\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Level 3: Primary Outcomes\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Level 4: \"FEV1 improved 12.3% (p<0.001)\"\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Level 3: Adverse Events\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ Level 4: \"Nausea (23%), vomiting (15%)...\"\n",
    "‚îî‚îÄ‚îÄ Level 2: DISCUSSION SECTION\n",
    "```\n",
    "\n",
    "### The Four Levels\n",
    "\n",
    "| Level | Name | Content | Weight | When to Use |\n",
    "|-------|------|---------|--------|-------------|\n",
    "| **1** | Document | Title, authors, summary | 0.1 | \"Tell me about...\" |\n",
    "| **2** | Section | Complete sections | 0.2 | \"What methods?\" |\n",
    "| **3** | Subsection | Detailed components | 0.4 | \"What were primary outcomes?\" |\n",
    "| **4** | Paragraph | Specific statements | 0.6-0.7 | \"What was the p-value?\" |\n",
    "\n",
    "### Key Insight üí°\n",
    "\n",
    "**Weights indicate importance for different query types:**\n",
    "- Higher weight (0.6-0.7) = More important for **specific** queries\n",
    "- Lower weight (0.1) = More important for **broad** queries\n",
    "\n",
    "This is the **magic** of multi-level chunking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Representation\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ LEVEL 1: Document Chunk (Weight: 0.1)                      ‚îÇ\n",
    "‚îÇ \"Antifungal Therapies for ABPA - Smith et al. - Quality A\" ‚îÇ\n",
    "‚îÇ USE: Broad queries like \"Tell me about ABPA treatment\"      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚îÇ\n",
    "        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚Üì                  ‚Üì                  ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ LEVEL 2: Abstract‚îÇ ‚îÇ LEVEL 2: Methods ‚îÇ ‚îÇ LEVEL 2: Results ‚îÇ\n",
    "‚îÇ (Weight: 0.2)    ‚îÇ ‚îÇ (Weight: 0.2)    ‚îÇ ‚îÇ (Weight: 0.2)    ‚îÇ\n",
    "‚îÇ Complete section ‚îÇ ‚îÇ Complete section ‚îÇ ‚îÇ Complete section ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚îÇ                                          ‚îÇ\n",
    "        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚Üì            ‚Üì                             ‚Üì            ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ LEVEL 3:     ‚îÇ ‚îÇ LEVEL 3:     ‚îÇ      ‚îÇ LEVEL 3:     ‚îÇ ‚îÇ LEVEL 3:     ‚îÇ\n",
    "‚îÇ Background   ‚îÇ ‚îÇ Objectives   ‚îÇ      ‚îÇ Primary      ‚îÇ ‚îÇ Adverse      ‚îÇ\n",
    "‚îÇ (Weight: 0.4)‚îÇ ‚îÇ (Weight: 0.4)‚îÇ      ‚îÇ Outcomes     ‚îÇ ‚îÇ Events       ‚îÇ\n",
    "‚îÇ              ‚îÇ ‚îÇ              ‚îÇ      ‚îÇ (Weight: 0.4)‚îÇ ‚îÇ (Weight: 0.4)‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚îÇ                                      ‚îÇ\n",
    "        ‚Üì                                      ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ LEVEL 4:     ‚îÇ                      ‚îÇ LEVEL 4:     ‚îÇ\n",
    "‚îÇ \"ABPA is a   ‚îÇ                      ‚îÇ \"FEV1        ‚îÇ\n",
    "‚îÇ common...\"   ‚îÇ                      ‚îÇ improved     ‚îÇ\n",
    "‚îÇ (Weight: 0.6)‚îÇ                      ‚îÇ 12.3%...\"    ‚îÇ\n",
    "‚îÇ              ‚îÇ                      ‚îÇ (Weight: 0.7)‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Practical Example: Multi-Level Chunking <a name=\"example\"></a>\n",
    "\n",
    "Let's implement multi-level chunking for our sample document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLevelChunker:\n",
    "    \"\"\"Demonstrates multi-level chunking\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chunks = {'level_1': [], 'level_2': [], 'level_3': [], 'level_4': []}\n",
    "    \n",
    "    def create_level_1(self):\n",
    "        \"\"\"Document-level chunk\"\"\"\n",
    "        return {\n",
    "            'level': 1,\n",
    "            'content': 'Antifungal Therapies for ABPA in Cystic Fibrosis',\n",
    "            'metadata': {'quality': 'A', 'authors': 'Smith et al.', 'topic': 'ABPA'},\n",
    "            'weight': 0.1,\n",
    "            'use_case': 'Broad search, overview'\n",
    "        }\n",
    "    \n",
    "    def create_level_2(self):\n",
    "        \"\"\"Section-level chunks\"\"\"\n",
    "        return [\n",
    "            {'level': 2, 'section': 'Abstract', 'content': 'Background + Objectives + Methods summary', 'weight': 0.2},\n",
    "            {'level': 2, 'section': 'Methods', 'content': 'RCT with 45 CF patients, itraconazole 16 weeks', 'weight': 0.2},\n",
    "            {'level': 2, 'section': 'Results', 'content': 'Primary + secondary outcomes + adverse events', 'weight': 0.2}\n",
    "        ]\n",
    "    \n",
    "    def create_level_3(self):\n",
    "        \"\"\"Subsection-level chunks\"\"\"\n",
    "        return [\n",
    "            {'level': 3, 'section': 'Abstract', 'subsection': 'Background', \n",
    "             'content': 'ABPA is a common complication in CF patients', 'weight': 0.4},\n",
    "            {'level': 3, 'section': 'Results', 'subsection': 'Primary Outcomes',\n",
    "             'content': 'Mean FEV1% improved by 12.3% (95% CI: 8.7-15.9, p<0.001)', 'weight': 0.4},\n",
    "            {'level': 3, 'section': 'Results', 'subsection': 'Adverse Events',\n",
    "             'content': 'Nausea (23%), vomiting (15%), elevated liver enzymes (8%)', 'weight': 0.4}\n",
    "        ]\n",
    "    \n",
    "    def create_level_4(self):\n",
    "        \"\"\"Paragraph-level chunks\"\"\"\n",
    "        return [\n",
    "            {'level': 4, 'subsection': 'Primary Outcomes',\n",
    "             'content': 'Mean FEV1% predicted improved by 12.3% (95% CI: 8.7-15.9, p<0.001)',\n",
    "             'statistical_data': {'effect': '12.3%', 'ci': '8.7-15.9', 'p': '<0.001'},\n",
    "             'weight': 0.7},\n",
    "            {'level': 4, 'subsection': 'Adverse Events',\n",
    "             'content': 'Nausea occurred in 23% of patients in itraconazole group',\n",
    "             'weight': 0.6}\n",
    "        ]\n",
    "    \n",
    "    def display_all(self):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MULTI-LEVEL CHUNKING STRUCTURE\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        print(\"üìÑ LEVEL 1 (Weight: 0.1) - Document Overview\")\n",
    "        l1 = self.create_level_1()\n",
    "        print(f\"   Content: {l1['content']}\")\n",
    "        print(f\"   Metadata: {l1['metadata']}\")\n",
    "        print(f\"   Use: {l1['use_case']}\\n\")\n",
    "        \n",
    "        print(\"üìë LEVEL 2 (Weight: 0.2) - Sections\")\n",
    "        for chunk in self.create_level_2():\n",
    "            print(f\"   ‚îú‚îÄ {chunk['section']}: {chunk['content']}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"üìã LEVEL 3 (Weight: 0.4) - Subsections\")\n",
    "        for chunk in self.create_level_3():\n",
    "            print(f\"   ‚îú‚îÄ {chunk['section']} ‚Üí {chunk['subsection']}\")\n",
    "            print(f\"   ‚îÇ  {chunk['content']}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"üìù LEVEL 4 (Weight: 0.6-0.7) - Paragraphs\")\n",
    "        for chunk in self.create_level_4():\n",
    "            print(f\"   ‚îú‚îÄ {chunk['subsection']}\")\n",
    "            print(f\"   ‚îÇ  {chunk['content']}\")\n",
    "            if 'statistical_data' in chunk:\n",
    "                print(f\"   ‚îÇ  üìä Stats: {chunk['statistical_data']}\")\n",
    "        print()\n",
    "\n",
    "# Run the example\n",
    "chunker = MultiLevelChunker()\n",
    "chunker.display_all()\n",
    "\n",
    "print(\"\\n‚úÖ Notice how each level serves a different purpose!\")\n",
    "print(\"   Level 1: Quick overview\")\n",
    "print(\"   Level 2: Section summaries\")\n",
    "print(\"   Level 3: Detailed information\")\n",
    "print(\"   Level 4: Precise data with statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. How Search Works with Multi-Level Chunks <a name=\"search\"></a>\n",
    "\n",
    "### Important: Search is PARALLEL, not Sequential!\n",
    "\n",
    "‚ùå **WRONG** (Sequential):\n",
    "```\n",
    "Search Level 1 ‚Üí Get results ‚Üí Then search Level 2 ‚Üí Then Level 3 ‚Üí Then Level 4\n",
    "```\n",
    "\n",
    "‚úÖ **CORRECT** (Parallel):\n",
    "```\n",
    "Search ALL levels simultaneously ‚Üí Combine results with weights ‚Üí Rank by relevance\n",
    "```\n",
    "\n",
    "### The Search Process (6 Steps)\n",
    "\n",
    "1. **Query Analysis**: Understand what user is asking\n",
    "2. **Target Level Determination**: Decide which levels matter most\n",
    "3. **Parallel Search**: Search all target levels at once\n",
    "4. **Cross-Level Scoring**: Combine results with level weights\n",
    "5. **Re-ranking**: Advanced scoring for top results\n",
    "6. **Context Assembly**: Build hierarchical response\n",
    "\n",
    "Let's implement this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLevelSearch:\n",
    "    \"\"\"Simulates multi-level search\"\"\"\n",
    "    \n",
    "    def __init__(self, chunker):\n",
    "        self.chunker = chunker\n",
    "        self.all_chunks = {\n",
    "            1: [chunker.create_level_1()],\n",
    "            2: chunker.create_level_2(),\n",
    "            3: chunker.create_level_3(),\n",
    "            4: chunker.create_level_4()\n",
    "        }\n",
    "    \n",
    "    def analyze_query(self, query):\n",
    "        \"\"\"Step 1: Query Analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 1: QUERY ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "        \n",
    "        q_lower = query.lower()\n",
    "        \n",
    "        # Determine intent and target levels\n",
    "        if any(w in q_lower for w in ['p-value', 'percentage', 'ci', 'statistical']):\n",
    "            intent, levels = 'statistical', [3, 4]\n",
    "        elif any(w in q_lower for w in ['efficacy', 'outcome', 'side effect', 'adverse']):\n",
    "            intent, levels = 'specific', [3, 4]\n",
    "        elif any(w in q_lower for w in ['tell me', 'overview', 'about']):\n",
    "            intent, levels = 'broad', [1, 2]\n",
    "        else:\n",
    "            intent, levels = 'general', [1, 2, 3, 4]\n",
    "        \n",
    "        print(f\"üìä Intent: {intent}\")\n",
    "        print(f\"üéØ Target Levels: {levels}\")\n",
    "        print(f\"üí° Reason: {'Needs precise data' if intent in ['statistical', 'specific'] else 'Needs overview'}\")\n",
    "        \n",
    "        return {'intent': intent, 'levels': levels}\n",
    "    \n",
    "    def parallel_search(self, query, target_levels):\n",
    "        \"\"\"Step 2: Parallel Multi-Level Search\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 2: PARALLEL SEARCH (All levels searched simultaneously!)\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        keywords = [w for w in query.lower().split() if len(w) > 3]\n",
    "        print(f\"üîç Keywords: {keywords}\\n\")\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        for level in target_levels:\n",
    "            print(f\"\\nSearching Level {level}...\")\n",
    "            results = []\n",
    "            \n",
    "            for chunk in self.all_chunks[level]:\n",
    "                content = str(chunk.get('content', '')).lower()\n",
    "                score = sum(1 for kw in keywords if kw in content)\n",
    "                \n",
    "                if score > 0:\n",
    "                    weighted_score = score * chunk['weight']\n",
    "                    results.append({\n",
    "                        'chunk': chunk,\n",
    "                        'score': score,\n",
    "                        'weighted_score': weighted_score,\n",
    "                        'level': level\n",
    "                    })\n",
    "            \n",
    "            print(f\"  Found {len(results)} matches\")\n",
    "            for r in results[:2]:\n",
    "                print(f\"    Score: {r['score']}, Weighted: {r['weighted_score']:.2f}\")\n",
    "            \n",
    "            all_results.extend(results)\n",
    "        \n",
    "        return sorted(all_results, key=lambda x: x['weighted_score'], reverse=True)\n",
    "    \n",
    "    def rerank(self, results, top_k=5):\n",
    "        \"\"\"Step 3: Re-ranking\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 3: RE-RANKING TOP RESULTS\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        top = results[:top_k]\n",
    "        \n",
    "        for i, r in enumerate(top, 1):\n",
    "            stat_bonus = 0.3 if 'statistical_data' in r['chunk'] else 0\n",
    "            r['final_score'] = r['weighted_score'] + stat_bonus\n",
    "            \n",
    "            print(f\"{i}. Level {r['level']} (Initial: {r['weighted_score']:.2f}, \"\n",
    "                  f\"Bonus: +{stat_bonus:.1f}, Final: {r['final_score']:.2f})\")\n",
    "            print(f\"   {r['chunk']['content'][:70]}...\")\n",
    "            if 'statistical_data' in r['chunk']:\n",
    "                print(f\"   üìä {r['chunk']['statistical_data']}\")\n",
    "        \n",
    "        return sorted(top, key=lambda x: x['final_score'], reverse=True)\n",
    "    \n",
    "    def assemble_context(self, results):\n",
    "        \"\"\"Step 4: Context Assembly\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 4: HIERARCHICAL CONTEXT ASSEMBLY\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        groups = {}\n",
    "        for r in results:\n",
    "            level = r['level']\n",
    "            if level not in groups:\n",
    "                groups[level] = []\n",
    "            groups[level].append(r)\n",
    "        \n",
    "        if 4 in groups:\n",
    "            print(\"üìù PRIMARY (Level 4 - 60% weight):\")\n",
    "            for r in groups[4][:2]:\n",
    "                print(f\"   ‚Ä¢ {r['chunk']['content']}\")\n",
    "        \n",
    "        if 3 in groups:\n",
    "            print(\"\\nüìã SUPPORTING (Level 3 - 40% weight):\")\n",
    "            for r in groups[3][:2]:\n",
    "                print(f\"   ‚Ä¢ {r['chunk']['content']}\")\n",
    "        \n",
    "        if 2 in groups:\n",
    "            print(\"\\nüìë BACKGROUND (Level 2 - 20% weight):\")\n",
    "            for r in groups[2][:1]:\n",
    "                print(f\"   ‚Ä¢ Section: {r['chunk']['section']}\")\n",
    "        \n",
    "        if 1 in groups:\n",
    "            print(\"\\nüìÑ METADATA (Level 1 - 10% weight):\")\n",
    "            for r in groups[1][:1]:\n",
    "                print(f\"   ‚Ä¢ {r['chunk']['content']}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Context ready for LLM!\")\n",
    "    \n",
    "    def search(self, query):\n",
    "        \"\"\"Complete search\"\"\"\n",
    "        analysis = self.analyze_query(query)\n",
    "        results = self.parallel_search(query, analysis['levels'])\n",
    "        \n",
    "        if not results:\n",
    "            print(\"\\n‚ö†Ô∏è No results found\")\n",
    "            return\n",
    "        \n",
    "        ranked = self.rerank(results)\n",
    "        self.assemble_context(ranked)\n",
    "        return ranked\n",
    "\n",
    "# Create search engine\n",
    "search = MultiLevelSearch(chunker)\n",
    "print(\"\\n‚úÖ Search engine initialized. Ready for queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Complete Query Flow Examples <a name=\"flow\"></a>\n",
    "\n",
    "Let's see how different types of queries are handled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Statistical Query (Needs Level 4)\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# EXAMPLE 1: STATISTICAL QUERY\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "search.search(\"What was the FEV1 improvement with itraconazole?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Safety Query (Needs Levels 3-4)\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# EXAMPLE 2: SAFETY QUERY\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "search.search(\"What are the side effects of itraconazole?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Broad Overview (Needs Levels 1-2)\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# EXAMPLE 3: BROAD OVERVIEW QUERY\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "search.search(\"Tell me about ABPA treatment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Interactive Exercises <a name=\"exercises\"></a>\n",
    "\n",
    "### Exercise 1: Query Classification\n",
    "\n",
    "For each query, determine:\n",
    "1. What is the intent?\n",
    "2. Which levels should be searched?\n",
    "3. Why?\n",
    "\n",
    "Try these queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "exercise_queries = [\n",
    "    \"What is the p-value for the primary outcome?\",\n",
    "    \"Tell me about this study\",\n",
    "    \"What methods were used?\",\n",
    "    \"How many patients had nausea?\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 1: Classify These Queries\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for q in exercise_queries:\n",
    "    print(f\"\\nQuery: \\\"{q}\\\"\")\n",
    "    print(\"Your answer:\")\n",
    "    print(\"  Intent: ___________\")\n",
    "    print(\"  Target Levels: ___________\")\n",
    "    print(\"  Reasoning: ___________\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nüí° Run search.analyze_query() on each to check your answers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Understanding Weights\n",
    "\n",
    "**Question**: Why does Level 4 have weight 0.6-0.7 while Level 1 has weight 0.1?\n",
    "\n",
    "**Think about:**\n",
    "- What information is at each level?\n",
    "- Which gives the most precise answers?\n",
    "- Which gives the broadest overview?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Compare the impact of weights\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 2: Weight Impact\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Scenario: User asks 'What was the p-value?'\\n\")\n",
    "\n",
    "print(\"Level 1 (Weight 0.1):\")\n",
    "print(\"  Content: 'Antifungal Therapies for ABPA'\")\n",
    "print(\"  Keyword matches: 0\")\n",
    "print(\"  Score: 0 √ó 0.1 = 0\\n\")\n",
    "\n",
    "print(\"Level 4 (Weight 0.7):\")\n",
    "print(\"  Content: 'FEV1 improved by 12.3% (p<0.001)'\")\n",
    "print(\"  Keyword matches: 1 ('p-value' found)\")\n",
    "print(\"  Score: 1 √ó 0.7 = 0.7\\n\")\n",
    "\n",
    "print(\"‚úÖ Result: Level 4 wins! Higher weight + relevant content = Best match\")\n",
    "print(\"\\nüí° The weight system ensures specific queries get specific answers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Context Assembly\n",
    "\n",
    "**Question**: Why combine results from multiple levels instead of just using the top result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXERCISE 3: Single-Level vs Multi-Level Response\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Query: 'What was the efficacy of itraconazole?'\\n\")\n",
    "\n",
    "print(\"‚ùå SINGLE-LEVEL (Only Level 4):\")\n",
    "print(\"  'Mean FEV1% improved by 12.3% (95% CI: 8.7-15.9, p<0.001)'\")\n",
    "print(\"\\n  Problems:\")\n",
    "print(\"    ‚Ä¢ What study is this from?\")\n",
    "print(\"    ‚Ä¢ Who were the participants?\")\n",
    "print(\"    ‚Ä¢ What was the study design?\")\n",
    "print(\"    ‚Ä¢ Is this study reliable?\\n\")\n",
    "\n",
    "print(\"‚úÖ MULTI-LEVEL (Combined):\")\n",
    "print(\"  Level 4: 'FEV1 improved 12.3% (95% CI: 8.7-15.9, p<0.001)'\")\n",
    "print(\"  Level 3: 'Primary outcome: lung function at 16 weeks'\")\n",
    "print(\"  Level 2: 'RCT with 45 CF patients'\")\n",
    "print(\"  Level 1: 'Quality A study by Smith et al.'\")\n",
    "print(\"\\n  ‚ú® User gets complete, trustworthy answer with context!\")\n",
    "\n",
    "print(\"\\nüí° Multi-level context = Better understanding + Higher trust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary and Key Takeaways <a name=\"summary\"></a>\n",
    "\n",
    "### üéØ Core Concepts\n",
    "\n",
    "1. **Multi-Level Hierarchy**\n",
    "   - Level 1: Document overview (0.1 weight)\n",
    "   - Level 2: Major sections (0.2 weight)\n",
    "   - Level 3: Subsections (0.4 weight)\n",
    "   - Level 4: Paragraphs (0.6-0.7 weight)\n",
    "\n",
    "2. **Different Levels, Different Purposes**\n",
    "   - Broad queries ‚Üí Levels 1-2\n",
    "   - Specific queries ‚Üí Levels 3-4\n",
    "   - Statistical queries ‚Üí Level 4\n",
    "\n",
    "3. **Parallel Search**\n",
    "   - ‚ùå NOT sequential (Level 1 ‚Üí 2 ‚Üí 3 ‚Üí 4)\n",
    "   - ‚úÖ All levels searched simultaneously\n",
    "   - Results combined with level-specific weights\n",
    "\n",
    "4. **Hierarchical Context**\n",
    "   - Primary (Level 4): Most specific\n",
    "   - Supporting (Level 3): Detailed context\n",
    "   - Background (Levels 1-2): Overview\n",
    "\n",
    "### üöÄ Advantages\n",
    "\n",
    "| Aspect | Traditional | Multi-Level |\n",
    "|--------|-------------|-------------|\n",
    "| Granularity | Fixed | Adaptive |\n",
    "| Context | Lost | Preserved |\n",
    "| Precision | Same for all | Level-specific |\n",
    "| Flexibility | One-size-fits-all | Query-adaptive |\n",
    "| Relationships | None | Hierarchical |\n",
    "\n",
    "### ‚úÖ When to Use Multi-Level Chunking\n",
    "\n",
    "**Good for:**\n",
    "- üìÑ Structured documents (papers, reports, medical reviews)\n",
    "- üéØ When precision matters (medical, legal, technical)\n",
    "- üîç Users need both overview AND details\n",
    "- üìä Documents with clear hierarchy\n",
    "\n",
    "**Not ideal for:**\n",
    "- üì± Unstructured text (social media, blogs)\n",
    "- üìù Very short documents\n",
    "- üåê No clear sections\n",
    "- üîé Simple keyword search sufficient\n",
    "\n",
    "### üí° The Big Picture\n",
    "\n",
    "Multi-level chunking is like a **zoom lens**:\n",
    "- **Zoomed out** (Levels 1-2): See the big picture\n",
    "- **Zoomed in** (Levels 3-4): See specific details\n",
    "- **Adaptive**: Automatically adjusts to user needs\n",
    "\n",
    "### üìö What's Next?\n",
    "\n",
    "1. **Implementation**: Build multi-level chunking for your documents\n",
    "2. **Embedding**: Generate embeddings for each level\n",
    "3. **Vector DB**: Store chunks with hierarchical relationships\n",
    "4. **Retrieval**: Implement parallel search with re-ranking\n",
    "5. **Testing**: Evaluate on different query types\n",
    "\n",
    "### ‚úÖ Checklist\n",
    "\n",
    "- [ ] I understand the four levels and their purposes\n",
    "- [ ] I know why different levels have different weights\n",
    "- [ ] I understand that search is parallel, not sequential\n",
    "- [ ] I know how query type determines target levels\n",
    "- [ ] I understand hierarchical context assembly\n",
    "- [ ] I can explain advantages over traditional chunking\n",
    "- [ ] I know when to use multi-level chunking\n",
    "\n",
    "**If you checked all boxes, congratulations! You understand multi-level chunking!** üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìñ Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- `Expert_RAG_System_Approach.md`: Overall RAG system design\n",
    "- `RAG_System_Flowchart.md`: Complete system flowchart\n",
    "- `Multi_Level_Chunking_Search_Flowchart.md`: Detailed search process\n",
    "\n",
    "### Research Papers\n",
    "- Dense Passage Retrieval (Karpukhin et al., 2020)\n",
    "- BERT (Devlin et al., 2018)\n",
    "- Retrieval-Augmented Generation (Lewis et al., 2020)\n",
    "\n",
    "### Implementation Tools\n",
    "- **LangChain**: Multi-vector retriever\n",
    "- **LlamaIndex**: Hierarchical node parsing\n",
    "- **Weaviate**: Multi-vector search\n",
    "\n",
    "---\n",
    "\n",
    "**Created**: October 2025\n",
    "**For**: Cochrane RAG System\n",
    "**Purpose**: Educational tutorial on multi-level chunking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
